{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# üìò Sesi√≥n 12: Proyecto Final Integrador\n\n---\n\n## üéØ Objetivos\n\n- Aplicar todos los conceptos del curso\n- Realizar an√°lisis exploratorio completo\n- Crear visualizaciones profesionales\n- Implementar modelo de ML end-to-end\n- Documentar y presentar resultados\n\n---\n\n## üìã Proyecto: Predicci√≥n de Precios de Viviendas\n\nEn este proyecto integrador, trabajaremos con un dataset de viviendas para:\n1. Explorar y limpiar los datos\n2. Visualizar patrones y relaciones\n3. Preprocesar para ML\n4. Entrenar y evaluar modelos\n5. Interpretar resultados"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_theme(style='whitegrid')\n%matplotlib inline"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Carga y Exploraci√≥n de Datos"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Crear dataset sint√©tico de viviendas\nnp.random.seed(42)\nn = 500\n\ndf = pd.DataFrame({\n    'metros_cuadrados': np.random.randint(40, 300, n),\n    'habitaciones': np.random.randint(1, 6, n),\n    'ba√±os': np.random.randint(1, 4, n),\n    'antig√ºedad': np.random.randint(0, 50, n),\n    'zona': np.random.choice(['Centro', 'Norte', 'Sur', 'Este', 'Oeste'], n),\n    'tiene_garaje': np.random.choice([0, 1], n),\n    'tiene_piscina': np.random.choice([0, 1], n, p=[0.8, 0.2]),\n    'planta': np.random.randint(1, 10, n)\n})\n\n# Precio basado en features + ruido\ndf['precio'] = (\n    df['metros_cuadrados'] * 2500 +\n    df['habitaciones'] * 15000 +\n    df['ba√±os'] * 10000 -\n    df['antig√ºedad'] * 1000 +\n    df['tiene_garaje'] * 20000 +\n    df['tiene_piscina'] * 30000 +\n    df['zona'].map({'Centro': 50000, 'Norte': 30000, 'Sur': 20000, 'Este': 25000, 'Oeste': 15000}) +\n    np.random.normal(0, 20000, n)\n)\n\ndf['precio'] = df['precio'].clip(lower=50000)  # Precio m√≠nimo\n\nprint(\"Primeras filas:\")\nprint(df.head())"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Informaci√≥n del dataset\nprint(\"\\nüìä Informaci√≥n del Dataset:\")\nprint(f\"Dimensiones: {df.shape}\")\nprint(f\"\\nTipos de datos:\")\nprint(df.dtypes)\nprint(f\"\\nValores nulos:\")\nprint(df.isnull().sum())"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Estad√≠sticas descriptivas\nprint(\"üìà Estad√≠sticas:\")\nprint(df.describe().round(2))"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. An√°lisis Exploratorio (EDA)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Distribuci√≥n del precio (target)\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nsns.histplot(df['precio'], kde=True, ax=axes[0])\naxes[0].set_title('Distribuci√≥n del Precio')\naxes[0].set_xlabel('Precio (‚Ç¨)')\n\nsns.boxplot(data=df, x='zona', y='precio', ax=axes[1])\naxes[1].set_title('Precio por Zona')\naxes[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Matriz de correlaci√≥n\nfig, ax = plt.subplots(figsize=(10, 8))\n\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\ncorr_matrix = df[numeric_cols].corr()\n\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\nsns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n            center=0, ax=ax)\nax.set_title('Matriz de Correlaci√≥n')\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Relaciones con el precio\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nsns.scatterplot(data=df, x='metros_cuadrados', y='precio', hue='zona', alpha=0.6, ax=axes[0,0])\naxes[0,0].set_title('Precio vs Metros Cuadrados')\n\nsns.boxplot(data=df, x='habitaciones', y='precio', ax=axes[0,1])\naxes[0,1].set_title('Precio por Habitaciones')\n\nsns.scatterplot(data=df, x='antig√ºedad', y='precio', alpha=0.5, ax=axes[1,0])\naxes[1,0].set_title('Precio vs Antig√ºedad')\n\nsns.boxplot(data=df, x='tiene_garaje', y='precio', ax=axes[1,1])\naxes[1,1].set_title('Precio con/sin Garaje')\naxes[1,1].set_xticklabels(['Sin Garaje', 'Con Garaje'])\n\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Preprocesamiento"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Preparar features\ndf_model = df.copy()\n\n# One-hot encoding para zona\ndf_model = pd.get_dummies(df_model, columns=['zona'], prefix='zona')\n\n# Separar features y target\nX = df_model.drop('precio', axis=1)\ny = df_model['precio']\n\nprint(f\"Features: {X.shape}\")\nprint(f\"Columnas: {X.columns.tolist()}\")"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Split train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Modelado"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Comparar m√∫ltiples modelos\nmodelos = {\n    'Linear Regression': LinearRegression(),\n    'Ridge': Ridge(alpha=1.0),\n    'Lasso': Lasso(alpha=1.0),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n}\n\nresultados = []\n\nfor nombre, modelo in modelos.items():\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('model', modelo)\n    ])\n    \n    # Cross-validation\n    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n    \n    # Entrenar y evaluar en test\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    \n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    resultados.append({\n        'Modelo': nombre,\n        'CV R¬≤ (mean)': cv_scores.mean(),\n        'CV R¬≤ (std)': cv_scores.std(),\n        'Test RMSE': rmse,\n        'Test MAE': mae,\n        'Test R¬≤': r2\n    })\n    \n    print(f\"{nombre}: R¬≤={r2:.4f}, RMSE={rmse:,.0f}‚Ç¨\")\n\ndf_resultados = pd.DataFrame(resultados)\nprint(\"\\nüìä Resumen de Modelos:\")\nprint(df_resultados.round(4))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Visualizar comparaci√≥n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# R¬≤ Score\nsns.barplot(data=df_resultados, x='Modelo', y='Test R¬≤', ax=axes[0], palette='viridis')\naxes[0].set_title('R¬≤ Score por Modelo')\naxes[0].tick_params(axis='x', rotation=45)\n\n# RMSE\nsns.barplot(data=df_resultados, x='Modelo', y='Test RMSE', ax=axes[1], palette='viridis')\naxes[1].set_title('RMSE por Modelo (‚Ç¨)')\naxes[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. An√°lisis del Mejor Modelo"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Entrenar mejor modelo (Gradient Boosting o el mejor seg√∫n resultados)\nbest_model = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', GradientBoostingRegressor(n_estimators=100, random_state=42))\n])\n\nbest_model.fit(X_train, y_train)\ny_pred = best_model.predict(X_test)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Predicciones vs Reales\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Scatter plot\naxes[0].scatter(y_test, y_pred, alpha=0.5)\naxes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\naxes[0].set_xlabel('Precio Real (‚Ç¨)')\naxes[0].set_ylabel('Precio Predicho (‚Ç¨)')\naxes[0].set_title('Predicciones vs Valores Reales')\n\n# Residuos\nresiduos = y_test - y_pred\naxes[1].hist(residuos, bins=30, edgecolor='black', alpha=0.7)\naxes[1].axvline(x=0, color='r', linestyle='--')\naxes[1].set_xlabel('Residuo (‚Ç¨)')\naxes[1].set_ylabel('Frecuencia')\naxes[1].set_title('Distribuci√≥n de Residuos')\n\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Feature Importance\nfeature_importance = best_model.named_steps['model'].feature_importances_\nfeature_names = X.columns\n\ndf_importance = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': feature_importance\n}).sort_values('Importance', ascending=True)\n\nplt.figure(figsize=(10, 8))\nplt.barh(df_importance['Feature'], df_importance['Importance'])\nplt.xlabel('Importancia')\nplt.title('Importancia de Features - Gradient Boosting')\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Conclusiones y Recomendaciones\n\n### üìä Hallazgos Principales:\n\n1. **Distribuci√≥n de Precios**: El precio promedio es X‚Ç¨ con una distribuci√≥n...\n\n2. **Variables m√°s Importantes**:\n   - Metros cuadrados (correlaci√≥n m√°s alta)\n   - Zona (Centro tiene precios m√°s altos)\n   - N√∫mero de habitaciones\n\n3. **Rendimiento del Modelo**:\n   - El mejor modelo fue Gradient Boosting con R¬≤ de X\n   - Error promedio de predicci√≥n: X‚Ç¨\n\n### üéØ Recomendaciones:\n\n1. Recopilar m√°s datos sobre caracter√≠sticas adicionales\n2. Considerar variables externas (distancia a transporte, servicios)\n3. Segmentar modelos por zona para mayor precisi√≥n"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## üìù Ejercicios Adicionales"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Ejercicio 1: Implementar GridSearchCV para optimizar hiperpar√°metros\n# Tu c√≥digo aqu√≠"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Ejercicio 2: Crear funci√≥n predict_price(caracteristicas)\n# Tu c√≥digo aqu√≠"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Ejercicio 3: Implementar el mismo modelo con PyTorch\n# Tu c√≥digo aqu√≠"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## üéì Resumen del Curso\n\n### Sesiones Completadas:\n\n1. ‚úÖ Fundamentos de Estructura de C√≥digo\n2. ‚úÖ PEP8 y C√≥digo Profesional\n3. ‚úÖ Funciones Avanzadas y Recursividad\n4. ‚úÖ Generadores e Iteradores\n5. ‚úÖ NumPy\n6. ‚úÖ Pandas B√°sico\n7. ‚úÖ Pandas Avanzado\n8. ‚úÖ Matplotlib\n9. ‚úÖ Seaborn\n10. ‚úÖ Scikit-learn\n11. ‚úÖ PyTorch\n12. ‚úÖ Proyecto Final\n\n### üöÄ Pr√≥ximos Pasos:\n\n- Practicar con datasets reales de Kaggle\n- Profundizar en Deep Learning\n- Explorar MLOps y deployment\n- Contribuir a proyectos open source\n\n**¬°Felicidades por completar el curso!** üéâ"]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
